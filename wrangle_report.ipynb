{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " WeRateDogs is a Twitter account that rates dogs with humorous content about the dog and the project report documents the steps taken to gather, assess, clean and store the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering data\n",
    "- Import relevant libraries\n",
    "- Loading the provided twitter archive enhanced dataset. The dataframe is df_1\n",
    "- Downloading file containing twitter image predictions programmatically, the dataframe is df_2\n",
    "- Queried the Twitter data, the dataframe is df_3:\n",
    "     - Queried twitter data using twitter API\n",
    "     - Stored each tweet in as JSON data in tweet_json.txt file\n",
    "     - saved each tweet's JSON data as a newline\n",
    "     - wrote and opened JSON data as tweet_json.text\n",
    "- Then I Read the **tweet_json.txt** into a pandas dataframe.\n",
    "- I used `.head()`,`.shape` to get a glimpse of how the data looks like. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in this section I detected and documented quality issues and tidiness issuess. I used bth visual and programmatic assessment.\n",
    "\n",
    "### **Assess tweet_archive(df_1)**, **Image predictions data(df_2)** and **Tweet_json data**\n",
    "\n",
    "- I visually assessed the three datasets and documented issues detected.\n",
    "- Generally, I used  `.head()`,`.sample()`,  `.tail()`,`.shape`,`.info()`,`describe()`,`.isnull()`, `.duplicated()`, `.unique()` to assess the data programmatically. \n",
    "\n",
    "- Below is a list of quality and tidiness issues documented.\n",
    "\n",
    "### Data Quality issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_1(twitter_archive_enhanced)`\n",
    "\n",
    "#### visual assessment\n",
    "1. These columns contain null values:in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp, expanded_urls\n",
    "\n",
    "#### programmatic assessment\n",
    "1. Erroneous data type for timestamp: it is an object instead of datetime\n",
    "\n",
    "2. Erroneous data type: retweeted_status_timestamp(it is object instead of datetime)\n",
    "\n",
    "3. Erroneous data type in the tweet id column is in int instead of string\n",
    "\n",
    "4. Invalid/incorrect dog names in the name columns: such as 'a', 'an', 'None'\n",
    "5. The 'doggo, 'floofer', 'pupper', and 'puppo' columns have lots of 'None' values.\n",
    "\n",
    "6. Source' content is unreadable, there are 4 unique sources: Twitter for iPhone, Vine - Make a Scene, Twitter Web Client, TweetDeck.\n",
    "\n",
    "7. There are tweets that having 'rating_numerator' with incorrect values, that weren't extracted well and there are some huge number of tweets with rating numerator > 10 with a maximum value 1776, which doesn't make sense.\n",
    "\n",
    "8. Erroneous datatype rating numerator\n",
    "\n",
    "9. Some rating in denominator are >10 and some ratings in numerators are huge\n",
    "\n",
    "10. columns for rating_numerator to form a column called rating.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_2(image predictions)`\n",
    "\n",
    "1. Erroneous data type: The twitter_id is int instead of string\n",
    "\n",
    "2. Values in columns 'p1', 'p2', and 'p3' don't have consistent format, it has both lowercase and uppercase values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_3(tweet_json)`\n",
    "\n",
    "1. Erroneous data type: id column is int instead of string\n",
    "\n",
    "2. Missing values: in_reply_to_status_id,in_reply_to_status_id_str, in_reply_to_user_id,in_reply_to_user_id_str,in_reply_to_screen_name\n",
    "\n",
    "3. Missing values in user, coordinates, place, contributors, possibly_sensitive,possibly_sensitive_appealable.\n",
    "\n",
    "4. Missing values in retweeted_status, quoted_status_id, quoted_status_id_str\tquoted_status_permalink\tquoted_status and,  extended_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Assesement\n",
    "`tweet_json` and `tweet_archive`\n",
    "1. unnecessary columns in tweet_json dataset: 'created_at','id_str', 'full_text', 'truncated', 'display_text_range', 'entities', 'extended_entities', 'source', 'in_reply_to_status_id','in_reply_to_status_id_str','in_reply_to_user_id ','in_reply_to_user_id_str',' in_reply_to_screen_name ','user', 'geo','coordinates','place','contributors',' is_quote_status','possibly_sensitive','possibly_sensitive_appealable','lang',' retweeted_status', 'quoted_status_id','quoted_status_id_str','quoted_status_permalink','quoted_status'\n",
    "\n",
    "- Dropped columns don't need cleaning for NAN values since they are gone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_1(twitter_archive_enhanced)`\n",
    "\n",
    "1. Columns for doggo, floofer, pupper and puppo are categories of different dog stages and should be in one column called 'dog stage'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_2(image predictions)`\n",
    "1. Multiple dog prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_3(tweet_json)`\n",
    "1. The column label for IDs should be the same across all the three datasets\n",
    "\n",
    "#### General Assessment: Tidiness issues\n",
    "\n",
    "1. We have three different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Quality issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_1(twitter_archive_enhanced)`\n",
    "1. Dropped columns containing null values:in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp, expanded_urls.\n",
    "2. Converted timestamp datatype from object to datetime.\n",
    "3. Converted tweet_id column data type from int to string\n",
    "4. Replaced the wrong names for dogs which are in lowercase with NaN values\n",
    "5. Replaced the 'None' values with NaN values in the `'doggo, 'floofer', 'pupper', and 'puppo'` columns\n",
    "6. Renamed values in source column to iPhone, WebClient, Vine, TweetDeck\n",
    "7. Extracted numerator rating from text column and denominator rating\n",
    "8. Converted the numerator and denominator rating data type from int to float\n",
    "9. keept rows where numerator is between 1-14 and denominator is equal to 10 to normalize the data. \n",
    "10. Dropped the rating_denominator column: all values in the rating_denominator column are equal to 10 hence no need for this column anymore, rename the rating_numerator column to 'rating'\n",
    "\n",
    "`df_2(image predictions)`\n",
    "- Converted twitter_id column datatype from int to string \n",
    "- removed '_' and capitalize names in p1, p2, p3 columns to have consisted in the format of the data. \n",
    "\n",
    "\n",
    "`df_3(tweet_json)`\n",
    "- Converted ID datatype from int to string\n",
    "- Renamed ID column to be same as that of twite_archive_advanced\n",
    "\n",
    "`General assessment-twitter_json dataset and twitter_archive`\n",
    "- dropped columns not necessary for analysis in tweet_json data('created_at','id_str', 'full_text', 'truncated', 'display_text_range', 'entities', 'extended_entities', 'source', 'in_reply_to_status_id','in_reply_to_status_id_str','in_reply_to_user_id ','in_reply_to_user_id_str',' in_reply_to_screen_name ','user', 'geo','coordinates','place','contributors',' is_quote_status','possibly_sensitive','possibly_sensitive_appealable','lang',' retweeted_status', 'quoted_status_id','quoted_status_id_str','quoted_status_permalink','quoted_status') and tweet_archive data(tweet_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning tidiness issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_1(twitter_archive_enhanced)`\n",
    "- Converted columns for doggo, floofer, pupper and puppo into rows and formed a column called stage for the different dog stages. Then identified tweets that have more than one dog stage and joined the stages using comma. For example,`tweet_id    855851453814013952` and `stage       doggo, puppo`\n",
    "Then then went ahead and merged the stage column with `df_1 clean` dataframe. \n",
    "\n",
    "`df_2(image predictions)`\n",
    "- Summarized the dog breeds(p1,p2,p3) into one column\n",
    "\n",
    "`General assessment-twitter_json dataset and twitter_archive`\n",
    "- Merged the three dataframes(df_1_clean df_2_clean and df_3_clean) to be one observational unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Saved gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
